{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 3: Model Training, Evaluation & Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - DEFINE\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, using the Ames, Iowa housing dataset, first, I'll establish simple baseline model using the OLS regression, and then I'll develop a few predictive models, namely, random forest, xgboost and lightgbm regression models and compare the performance of these models against the baseline with the aim to get better predictive performance. The implementation of similar models will potentially allow housing agencies, real-estate companies, banks, municipial governments and home buyers to make informed decisions with respect to market pricing.\n",
    "\n",
    "### Objective: \n",
    "- To build a predictive ML model with the MAE accuracy of less than 20000.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check versions of the Python and some key packages to ensure most recent version is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n",
      "Author: Vusal Babashov\n",
      "\n",
      "Last updated: 2021-03-17\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.8.2\n",
      "IPython version      : 7.21.0\n",
      "\n",
      "numpy     : 1.19.2\n",
      "mlxtend   : 0.18.0\n",
      "matplotlib: 3.3.4\n",
      "sklearn   : 0.24.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -a 'Vusal Babashov' -u -d -v -p numpy,mlxtend,matplotlib,sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install flake8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda update scikit-learn numpy matplotlib "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - DISCOVER\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, PolynomialFeatures\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression, RFECV, RFE\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, KFold, cross_validate\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score \n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from feature_engine import encoding as enc #RareLabelEncoder, OrdinalEncoder\n",
    "from feature_engine.selection import SelectByTargetMeanPerformance, DropConstantFeatures, DropFeatures \n",
    "from feature_engine.imputation import MeanMedianImputer\n",
    "from feature_engine.creation import CombineWithReferenceFeature, MathematicalCombination\n",
    "\n",
    "#your info here\n",
    "__author__ = \"Vusal Babashov\"\n",
    "__email__ = \"vbabashov@gmail.com\"\n",
    "__website__ = 'https://vbabashov.github.io'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = \"data/train.csv\"\n",
    "test_feature_file = \"data/test.csv\"\n",
    "\n",
    "def load_file(file):\n",
    "    '''loads csv to pd dataframe'''\n",
    "    return pd.read_csv(file)\n",
    "\n",
    "data_train_raw = load_file(train_file)\n",
    "feature_pred_raw  = load_file(test_feature_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand the data better, the full [EDA](https://github.com/vbabashov/house-prices/blob/main/price_prediction_EDA.ipynb) analysis are implemented in seperate notebooks due to size and readibility. \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PreProcessing Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>20</td>\n",
       "      <td>RH</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gar2</td>\n",
       "      <td>12500</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>74.0</td>\n",
       "      <td>13830</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>78.0</td>\n",
       "      <td>9978</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465</td>\n",
       "      <td>120</td>\n",
       "      <td>RL</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5005</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>HLS</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0  1461          20       RH         80.0    11622   Pave   NaN      Reg   \n",
       "1  1462          20       RL         81.0    14267   Pave   NaN      IR1   \n",
       "2  1463          60       RL         74.0    13830   Pave   NaN      IR1   \n",
       "3  1464          60       RL         78.0     9978   Pave   NaN      IR1   \n",
       "4  1465         120       RL         43.0     5005   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... ScreenPorch PoolArea PoolQC  Fence MiscFeature  \\\n",
       "0         Lvl    AllPub  ...         120        0    NaN  MnPrv         NaN   \n",
       "1         Lvl    AllPub  ...           0        0    NaN    NaN        Gar2   \n",
       "2         Lvl    AllPub  ...           0        0    NaN  MnPrv         NaN   \n",
       "3         Lvl    AllPub  ...           0        0    NaN    NaN         NaN   \n",
       "4         HLS    AllPub  ...         144        0    NaN    NaN         NaN   \n",
       "\n",
       "  MiscVal MoSold  YrSold  SaleType  SaleCondition  \n",
       "0       0      6    2010        WD         Normal  \n",
       "1   12500      6    2010        WD         Normal  \n",
       "2       0      3    2010        WD         Normal  \n",
       "3       0      6    2010        WD         Normal  \n",
       "4       0      1    2010        WD         Normal  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_pred_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 81)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_raw.shape # check the dimensions of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 80)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_pred_raw.shape # target variable SalePrice is to be predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_transform (df):\n",
    "    '''This function performs the log transformation of the target'''\n",
    "    df['SalePrice'] = np.log(df['SalePrice'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log Transformation of the target\n",
    "train_transformed_df = log_transform(data_train_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the EDA, we know that some of the columns have a lot of missing values. Below, I'll identify and drop the columns that have 80% (somewhat an arbitrary choice) or more of its values missing or coded as NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_missing_cols_df (df):\n",
    "    '''Identifies and drops the columns with 80% or hihgher proportion of missing data '''\n",
    "    dropped_cols = []  \n",
    "    for col in df.columns:\n",
    "        if df[col].isnull().sum()/df.shape[0] >= 0.8:\n",
    "            dropped_cols.append(col)\n",
    "    dropped_df=df.drop(columns=dropped_cols)\n",
    "    return dropped_df, dropped_cols  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean_df, missing_cols = drop_missing_cols_df(train_transformed_df) # determine and drop the missing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Alley', 'PoolQC', 'Fence', 'MiscFeature']"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_cols # These four columns are dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_clean_df = feature_pred_raw.drop(columns=missing_cols, axis=1) # Let's drop the same columns from the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Data dictionary file](http://jse.amstat.org/v19n3/decock/DataDocumentation.txt) specifies that columns have differnet data types. Below is the breakdown of the variables into nominal, ordinal and numerical types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "nominal = ['MSSubClass', 'MSZoning', 'Street', 'LandContour', 'LotConfig', \n",
    "                   'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle',\n",
    "                   'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', \n",
    "                   'Foundation', 'Heating', 'CentralAir', 'GarageType', 'MoSold',\n",
    "                   'SaleType', 'SaleCondition'] # removed Alley, MiscFeature, \n",
    "\n",
    "ordinal = ['LotShape', 'Utilities', 'LandSlope', 'OverallQual', 'OverallCond', \n",
    "                   'ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'BsmtExposure', \n",
    "                   'BsmtFinType1', 'BsmtFinType2', 'HeatingQC', 'Electrical', 'KitchenQual', \n",
    "                   'Functional', 'FireplaceQu', 'GarageFinish', 'GarageQual', 'GarageCond',\n",
    "                   'PavedDrive'] #removed PoolQC, Fence,\n",
    "\n",
    "\n",
    "numeric = ['Id','LotFrontage','LotArea','YearBuilt','YearRemodAdd','MasVnrArea','BsmtFinSF1',\n",
    "                  'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF','1stFlrSF','2ndFlrSF','LowQualFinSF','GrLivArea',\n",
    "                  'BsmtFullBath','BsmtHalfBath','FullBath','HalfBath','BedroomAbvGr','KitchenAbvGr', 'TotRmsAbvGrd',\n",
    "                  'Fireplaces','GarageCars','GarageArea','WoodDeckSF','OpenPorchSF','EnclosedPorch',\n",
    "                  '3SsnPorch','ScreenPorch','PoolArea','MiscVal', 'GarageYrBlt', 'YrSold'] # removed the SalePrice\n",
    "\n",
    "categorical = nominal+ordinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing_values (df, categorical_features, numeric_features):\n",
    "    ''' Imputes the continious columns with median and categorical columns with the mode value'''\n",
    "    imputer_con = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "    imputer_cat = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "    for col in categorical_features+numeric_features:\n",
    "        if df[col].isnull().sum() > 0:    \n",
    "            if col in categorical_features:              \n",
    "                df[col] = imputer_cat.fit_transform(df[col].values.reshape(-1,1))\n",
    "            elif col in numeric_features:  \n",
    "                df[col] = imputer_con.fit_transform(df[col].values.reshape(-1,1))\n",
    "    return df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imputed_df = impute_missing_values (train_clean_df, categorical, numeric)  #impute the categorical variables with the most frequent, or mode, and the numeric variables with the median\n",
    "pred_imputed_df  = impute_missing_values (pred_clean_df, categorical, numeric) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Below are ordered values for each ordinal variable as per the data dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordinal Category Values\n",
    "lot_shape = ['IR3','IR2','IR1','Reg']\n",
    "utilities = ['ELO', 'NoSeWa', 'NoSewr','AllPub']\n",
    "land_slope = ['Sev','Mod','Gtl']\n",
    "overall_qual = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]  # already in the ordinal structure\n",
    "overall_cond = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]  # already in the ordinal structure\n",
    "exter_qual = ['Po', 'Fa', 'TA', 'Gd', 'Ex']\n",
    "exter_cond = ['Po', 'Fa', 'TA', 'Gd', 'Ex']\n",
    "bsmt_qual  = ['NA', 'Po', 'Fa', 'TA', 'Gd', 'Ex']\n",
    "bsmt_cond  = ['NA', 'Po', 'Fa', 'TA', 'Gd', 'Ex']\n",
    "bsmt_exposure  = ['NA', 'No', 'Mn', 'Av', 'Gd']\n",
    "bsmt_fin_type1 = ['NA', 'Unf', 'LwQ', 'Rec', 'BLQ', 'ALQ', 'GLQ']\n",
    "bsmt_fin_type2 = ['NA', 'Unf', 'LwQ', 'Rec', 'BLQ', 'ALQ', 'GLQ']\n",
    "heating_qual = ['Po', 'Fa', 'TA', 'Gd', 'Ex']\n",
    "electrical = ['Mix', 'FuseP', 'FuseF', 'FuseA', 'SBrkr']\n",
    "kitchen_qual = ['Po', 'Fa', 'TA', 'Gd', 'Ex']\n",
    "functional = ['Sal', 'Sev', 'Maj2', 'Maj1', 'Mod', 'Min2', 'Min1', 'Typ']\n",
    "fire_place_qual = ['NA', 'Po', 'Fa', 'TA', 'Gd', 'Ex']\n",
    "garage_finish = ['NA', 'Unf', 'RFn', 'Fin']\n",
    "garage_qual = ['NA', 'Po', 'Fa', 'TA', 'Gd', 'Ex']\n",
    "garage_cond = ['NA', 'Po', 'Fa', 'TA', 'Gd', 'Ex']\n",
    "paved_drive = ['N', 'P', 'Y']\n",
    "\n",
    "ordinal_categories_list = [lot_shape , utilities, land_slope, overall_qual, overall_cond, exter_qual, exter_cond, bsmt_qual, \n",
    "                          bsmt_cond, bsmt_exposure, bsmt_fin_type1, bsmt_fin_type2, heating_qual, electrical, kitchen_qual,\n",
    "                          functional, fire_place_qual, garage_finish, garage_qual, garage_cond, paved_drive]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordinal_encoding (df, nominal_cols, ordinal_cols, ordinal_categories_list, numeric_cols):\n",
    "    '''This function encodes ordinal variables into ordinal encoding and combines wit the rest of the dataframe'''\n",
    "    ore = OrdinalEncoder(categories=ordinal_categories_list)\n",
    "    Z=ore.fit_transform(df[ordinal_cols])\n",
    "    list_of_frames=[df[nominal_cols].reset_index(drop=True), \n",
    "                    pd.DataFrame(Z,columns=ordinal_cols).reset_index(drop=True), \n",
    "                    df[numeric_cols].reset_index(drop=True)]\n",
    "                   # df['SalePrice'].reset_index(drop=True)]\n",
    "    return pd.concat(list_of_frames, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_enc_df  = ordinal_encoding (train_imputed_df, nominal, ordinal, ordinal_categories_list, numeric+['SalePrice']) # encode the ordinal variables as per specified orderd\n",
    "pred_enc_df   = ordinal_encoding (pred_imputed_df, nominal, ordinal, ordinal_categories_list, numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_month_string (df):\n",
    "    '''This function maps the numerical month names into string month names'''\n",
    "    d = { 1 : 'Jan',\n",
    "          2 : 'Feb',\n",
    "          3 : 'Mar',\n",
    "          4 : 'Apr',\n",
    "          5 : 'May',\n",
    "          6 : 'June',\n",
    "          7 : 'July',\n",
    "          8 : 'Aug',\n",
    "          9 : 'Sep',\n",
    "          10: 'Oct',\n",
    "          11: 'Nov',\n",
    "          12: 'Dec'\n",
    "    }\n",
    "    df['MoSold'] = df ['MoSold'].map(d)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_converted_df = convert_month_string(train_enc_df)\n",
    "pred_converted_df  = convert_month_string(pred_enc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_types (df):\n",
    "    '''This function coverts the categorical variables into object and numeric variables into int types'''\n",
    "    df[nominal] = df[nominal].astype('O')\n",
    "    df[ordinal] = df[ordinal].astype('int')\n",
    "    df[numeric] = df[numeric].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_types (train_converted_df)\n",
    "convert_types (pred_converted_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1168, 75), (292, 75), (1459, 75))"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pred = pred_converted_df.drop(columns=['Id'], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_converted_df.drop(['Id', 'SalePrice'], axis=1),train_converted_df['SalePrice'],\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape, X_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establish a baseline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used Ordinary Least Squares (OLS) Regression model results as a [baseline](https://github.com/vbabashov/house-prices/blob/main/baseline.ipynb) and obtained the following model accuracy.\n",
    "\n",
    "- MAE  for the Baseline Model: 24139.18\n",
    "- RMSE for the Baseline Model : 149478.70"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesize solution "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Th MAE is around 24000 with the engineered features. Let's try to come up with a predictive model with better accuracy. There are many supervised learning methods that can be developed. In this notebook, I'll explore the following tree-based techniques because of their recent successful applications in many domains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Random Forest\n",
    "- Xgboost \n",
    "- LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - DEVELOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the process, I'll look into creating features, tuning models, and training/validating models\n",
    "- model selection (i.e, hyperparameter tuning)\n",
    "- algorithm selection\n",
    "- model evaluation with the selected algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_rare_label (df_train, df_test, df_pred):\n",
    "    ''' This function encodes the rare nominal categories with the Rare label if number of categories is at least 4, cat is less than 5% of the total values'''\n",
    "    rare_enc = enc.RareLabelEncoder(tol = 0.05, n_categories=4, variables=nominal)\n",
    "    rare_enc.fit(df_train)\n",
    "    df_train = rare_enc.transform(df_train)\n",
    "    df_test  = rare_enc.transform(df_test)\n",
    "    df_pred  = rare_enc.transform(df_pred)\n",
    "    return df_train, df_test, df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_order_price(df_train, target_train, df_test, df_pred):\n",
    "    '''This function does the ordinal encoding according to mean prices on nominal variables'''\n",
    "    encoder = enc.OrdinalEncoder (encoding_method='ordered', variables = nominal)\n",
    "    encoder.fit(df_train, target_train)\n",
    "    df_train = encoder.transform(df_train)\n",
    "    df_test = encoder.transform(df_test)\n",
    "    return df_train, df_test, df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_features (df_train, df_test, df_pred):  \n",
    "    ''' This function  engineers several features e.g., time, bath count, and total area of the house'''  \n",
    "    # Years passed since \n",
    "    combinator = CombineWithReferenceFeature(\n",
    "        variables_to_combine=['YrSold'],\n",
    "        reference_variables=['YearBuilt', 'YearRemodAdd', 'GarageYrBlt'],\n",
    "        operations = ['sub']\n",
    "    )  \n",
    "    # drop the features\n",
    "    drop = DropFeatures(\n",
    "        features_to_drop=['YearBuilt','YrSold','YearRemodAdd', 'GarageYrBlt']\n",
    "    )\n",
    "    # total number of bathrooms\n",
    "    bath = MathematicalCombination(\n",
    "        variables_to_combine=['BsmtHalfBath', 'BsmtFullBath', 'FullBath', 'HalfBath'],\n",
    "        math_operations=['sum'],\n",
    "        new_variables_names=['TotalBath'],\n",
    "    )\n",
    "    # total area of house 1stfloor+2ndfloor+Totalbasement\n",
    "    area = MathematicalCombination(\n",
    "        variables_to_combine=['1stFlrSF', '2ndFlrSF', 'TotalBsmtSF'],\n",
    "        math_operations=['sum'],\n",
    "        new_variables_names=['TotalArea'],\n",
    "    )\n",
    "    \n",
    "    combinator.fit(df_train)\n",
    "    df_train = combinator.transform(df_train)\n",
    "    df_test = combinator.transform(df_test)\n",
    "    df_pred = combinator.transform(df_pred)\n",
    "    \n",
    "    drop.fit(df_train)\n",
    "    df_train = drop.transform (df_train)\n",
    "    df_test  = drop.transform (df_test)\n",
    "    df_pred  = drop.transform(df_pred)\n",
    "    \n",
    "    df_train = bath.fit_transform (df_train)\n",
    "    df_test  = bath.fit_transform (df_test)\n",
    "    df_pred  = bath.fit_transform(df_pred)\n",
    "\n",
    "    df_train = area.fit_transform (df_train)\n",
    "    df_test  = area.fit_transform (df_test)\n",
    "    df_pred  = area.fit_transform(df_pred)\n",
    "    \n",
    "    return df_train, df_test, df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, X_pred = encode_rare_label  (X_train, X_test, X_pred)\n",
    "X_train, X_test, X_pred = encode_order_price (X_train, y_train, X_test, X_pred)\n",
    "X_train, X_test, X_pred = engineer_features  (X_train, X_test, X_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm = LGBMRegressor(random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = lgbm.fit(X_train, y_train)\n",
    "test_pred  = lgbm.fit(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 0.16\n",
      " Test RMSE: 0.05\n",
      "\n",
      "Train R2: 0.85\n",
      " Test R2: 0.98\n",
      "\n",
      " Train MAE: 18771.69\n",
      "  Test MAE: 6544.92\n",
      "\n",
      " Train RMSE: 30663.40\n",
      "  Test RMSE: 18730.37\n"
     ]
    }
   ],
   "source": [
    "train_pred = lgbm.predict(X_train)\n",
    "test_pred = lgbm.predict(X_test)\n",
    "\n",
    "print('Train RMSE: %.2f'%  mean_squared_error(y_train,train_pred, squared=False))\n",
    "print(' Test RMSE: %.2f'%   mean_squared_error(y_test, test_pred, squared=False))\n",
    "print()\n",
    "print('Train R2: %.2f'%  r2_score(y_train, train_pred))\n",
    "print(' Test R2: %.2f'%  r2_score(y_test, test_pred))\n",
    "\n",
    "print ('\\n Train MAE: %.2f'%   mean_absolute_error(np.exp(y_train), np.exp(train_pred)))\n",
    "print ('  Test MAE: %.2f'%     mean_absolute_error(np.exp(y_test), np.exp(test_pred)))\n",
    "\n",
    "print ('\\n Train RMSE: %.2f'%   mean_squared_error(np.exp(y_train), np.exp(train_pred), squared = False))\n",
    "print ('  Test RMSE: %.2f'%     mean_squared_error(np.exp(y_test),  np.exp(test_pred), squared = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above results suggest some underfitting - e.g., high bias, low variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg1 = RandomForestRegressor(random_state=1)\n",
    "reg2 = XGBRegressor(random_state=1)\n",
    "reg3 = LGBMRegressor(random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build Pipelines\n",
    "pipe1 = Pipeline(steps=[ #('fea', SelectKBest(score_func=f_regression, k = 65)),\n",
    "                         ('pol', PolynomialFeatures()), \n",
    "                         ('reg1',reg1)])\n",
    "                        \n",
    "pipe2 = Pipeline(steps=[#('fea', SelectKBest(score_func=f_regression, k = 65)),\n",
    "                        ('pol', PolynomialFeatures()), \n",
    "                        ('reg2',reg2)])\n",
    "\n",
    "pipe3 = Pipeline(steps=[#('fea', SelectKBest(score_func=f_regression, k = 65)),\n",
    "                        ('pol', PolynomialFeatures()), \n",
    "                        ('reg3',reg3)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Accuracy Results (without parameter tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Mean Absolute Error (MAE) for the Random Forest: 17555.75\n",
      " Test R2: 0.87\n"
     ]
    }
   ],
   "source": [
    "pipe1.fit(X_train, y_train)\n",
    "y_pred = pipe1.predict(X_test)\n",
    "print ('\\n Mean Absolute Error (MAE) for the Random Forest: %.2f'%  mean_absolute_error(np.exp(y_test), np.exp(y_pred)))\n",
    "print(' Test R2: %.2f'%  r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Mean Absolute Error (MAE) for the Xgboost: 19173.90\n",
      " Test R2: 0.86\n"
     ]
    }
   ],
   "source": [
    "pipe2.fit(X_train, y_train)\n",
    "y_pred = pipe2.predict(X_test)\n",
    "print ('\\n Mean Absolute Error (MAE) for the Xgboost: %.2f'%  mean_absolute_error(np.exp(y_test), np.exp(y_pred)))\n",
    "print(' Test R2: %.2f'%  r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Mean Absolute Error (MAE) for the LightGBM: 16894.79\n",
      " Test R2: 0.87\n"
     ]
    }
   ],
   "source": [
    "pipe3.fit(X_train, y_train)\n",
    "y_pred = pipe3.predict(X_test)\n",
    "print ('\\n Mean Absolute Error (MAE) for the LightGBM: %.2f'%  mean_absolute_error(np.exp(y_test), np.exp(y_pred)))\n",
    "print(' Test R2: %.2f'%  r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the Models, With Different Parameters, and Algorithms Using Nested Cross Validation (i.e., 5x2Cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the Pipelines\n",
    "#Build Pipelines\n",
    "pipe1 = Pipeline(steps=[ ('fs',  SelectKBest(score_func=f_regression, k = 200)),\n",
    "                         ('pol', PolynomialFeatures()), \n",
    "                         ('reg1',reg1)])\n",
    "                        \n",
    "pipe2 = Pipeline(steps=[('fs', SelectKBest(score_func=f_regression, k = 200)),\n",
    "                        ('pol', PolynomialFeatures()), \n",
    "                        ('reg2',reg2)])\n",
    "\n",
    "pipe3 = Pipeline(steps=[('fs', SelectKBest(score_func=f_regression, k = 200)),\n",
    "                        ('pol', PolynomialFeatures()), \n",
    "                        ('reg3',reg3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the parameter grids for hyperparameter tuning, i.e, Model Selection\n",
    "param_grid1 = {'reg1__n_estimators': [500,1000],\n",
    "           #    'reg1__fs' : [100,150,200]\n",
    "               }\n",
    "\n",
    "param_grid2 = {\n",
    "          'reg2__colsample_bytree':[0.6, 1], \n",
    "          'reg2__eta': [0.01, 0.1],\n",
    "          'reg2__max_depth': [8,10],\n",
    "          'reg2__min_child_weight':[6,9], \n",
    "          'reg2__subsample' :[0.6, 0.8],\n",
    "        #  'reg2__fs' : [100,150,200]\n",
    "        }\n",
    "\n",
    "param_grid3 = {\n",
    "\n",
    "    \"reg3__num_leaves\": [6, 8, 20, 30],\n",
    "    \"reg3__max_depth\": [2, 4, 6, 8, 10],\n",
    "    \"reg3__n_estimators\": [50, 100, 200, 500],\n",
    "    \"reg3__colsample_bytree\": [0.3, 1.0],\n",
    "\n",
    "   }\n",
    " \n",
    "param_grid4 = {'reg4__alpha':[0.001, 0.01, 0.1],\n",
    "              # 'reg4__fs' : [100,150,200]\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up multiple GridSearchCV objects for model selection and algorithm comparison\n",
    "gridcvs = {}\n",
    "\n",
    "inner_cv = KFold(n_splits=2, shuffle=True, random_state=1)\n",
    "\n",
    "for pgrid, est, name in zip((param_grid1, param_grid2, param_grid3, param_grid4),\n",
    "                            (pipe1, pipe2, pipe3, pipe4),\n",
    "                            ('RForest', 'Xgboost', 'LightGBM' ,'Lasso')):\n",
    "      \n",
    "    gcv = GridSearchCV(estimator=est,\n",
    "                       param_grid=pgrid,\n",
    "                       scoring = 'neg_mean_absolute_error',\n",
    "                       #n_jobs=-1,\n",
    "                       cv=inner_cv,\n",
    "                       verbose=0,\n",
    "                       refit=True)\n",
    "    gridcvs[name] = gcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_cv = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "for name, gs_est in sorted(gridcvs.items()):\n",
    "    scores_dict = cross_validate(gs_est, \n",
    "                                 X=feature_train, \n",
    "                                 y=target_train,\n",
    "                                 verbose=0,\n",
    "                                 cv=outer_cv,\n",
    "                                 return_estimator=True,\n",
    "                                 #n_jobs=-1\n",
    "                                )\n",
    "\n",
    "    print(50 * '-', '\\n')\n",
    "    print('Algorithm:', name)\n",
    "    print('    Inner loop:')\n",
    "    \n",
    "    \n",
    "    for i in range(scores_dict['test_score'].shape[0]):\n",
    "\n",
    "        print('\\n      Best MAE Score (avg. of inner test folds) %.2f' % np.absolute(scores_dict['estimator'][i].best_score_))\n",
    "        print('        Best parameters:', scores_dict['estimator'][i].best_estimator_)\n",
    "        print('        MAE Score (on outer test fold) %.2f' % np.absolute(scores_dict['test_score'][i]))\n",
    "\n",
    "    print('\\n%s | outer test folds Ave. Score %.2f +/- %.2f' % \n",
    "          (name, np.absolute(scores_dict['test_score']).mean(), \n",
    "           np.absolute(scores_dict['test_score']).std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Model Selection (i.e., Hyperparameter Tuning) Once the Algorithm Selection is Made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2-fold cross validation on the best model, fit on the entire dataset\n",
    "gcv_model_select = GridSearchCV(estimator=pipe3,\n",
    "                                param_grid=param_grid3,\n",
    "                                scoring='neg_mean_absolute_error',\n",
    "                                n_jobs=-1,\n",
    "                                cv = 2,\n",
    "                                verbose=0,\n",
    "                                refit=True)\n",
    "\n",
    "gcv_model_select.fit(feature_train, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select best model and Test the Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the model with the lowest error as your \"production\" model\n",
    "best_model = gcv_model_select.best_estimator_\n",
    "\n",
    "train_ = mean_absolute_error(y_true=np.exp(target_train), y_pred=np.exp(best_model.predict(feature_train)))\n",
    "test_  = mean_absolute_error(y_true=np.exp(target_test),  y_pred=np.exp(best_model.predict(feature_test)))\n",
    "\n",
    "print('MAE score: %.2f (average over k-fold CV test folds)' %\n",
    "      np.absolute(gcv_model_select.best_score_))\n",
    "print('Best Parameters: %s' % gcv_model_select.best_params_)\n",
    "\n",
    "print('\\nTraining MAE for Best Model: %.2f' % (train_))\n",
    "print('Test MAE for Best Model: %.2f' % (test_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 - DEPLOY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automate pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write script that trains model on entire training set, saves model to disk,\n",
    "#and scores the \"test\" dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save your prediction to a csv file or optionally save them as a table in a SQL database\n",
    "#additionally, you want to save a visualization and summary of your prediction and feature importances\n",
    "#these visualizations and summaries will be extremely useful to business stakeholders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure efficacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll skip this step since we don't have the outcomes for the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
